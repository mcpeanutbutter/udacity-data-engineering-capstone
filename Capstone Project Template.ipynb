{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "## Data Engineering Capstone Project\n",
    "\n",
    "### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to its size, I process the \n",
    "df_sas = spark.read.parquet(\"sas_data\")\n",
    "df_airport = pd.read_csv(\"data/airport-codes_csv.csv\")\n",
    "df_demo = pd.read_csv(\"data/us-cities-demographics.csv\", sep=';')\n",
    "df_weather = pd.read_csv(\"temperature_data/GlobalLandTemperaturesByCountry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    \n",
    "    def clean_field(df, col, regex):\n",
    "        df[col] = df[col].str.extract(regex)\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col] = df[col].str.upper()\n",
    "        return df[col]\n",
    "    \n",
    "    lines=f.readlines()\n",
    "    \n",
    "    df_cntyl = pd.DataFrame(lines[9:297])\n",
    "    df_cntyl = df_cntyl[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_cntyl.columns = ['i94cntyl','country']\n",
    "    df_cntyl['country'] = clean_field(df_cntyl, 'country', r'\\'([^\\']+)\\'')\n",
    "    df_cntyl['i94cntyl'] = df_cntyl['i94cntyl'].astype(int)\n",
    "    \n",
    "    df_port = pd.DataFrame(lines[302:962])\n",
    "    df_port = df_port[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_port_comma_split = df_port[1].str.split(\",\", n=1, expand= True)\n",
    "    df_port[1] = df_port_comma_split[0]\n",
    "    df_port[2] = df_port_comma_split[1]\n",
    "    df_port.columns = ['i94port','port','addr']\n",
    "    df_port['i94port'] = clean_field(df_port, 'i94port', r'\\'([^\\']+)\\'')\n",
    "    df_port['port'] = clean_field(df_port, 'port', r'\\'([^\\']+)')\n",
    "    df_port['addr'] = clean_field(df_port, 'addr', r'([^\\']+)\\'')\n",
    "  \n",
    "    df_mode = pd.DataFrame(lines[972:976])\n",
    "    df_mode = df_mode[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_mode.columns = ['i94mode','mode']\n",
    "    df_mode['mode'] = clean_field(df_mode, 'mode', r'\\'([^\\']+)\\'')\n",
    "    df_mode['i94mode'] = clean_field(df_mode, 'i94mode', r'\\s+([^\\']+)')\n",
    "    \n",
    "    df_addr = pd.DataFrame(lines[981:1036])\n",
    "    df_addr = df_addr[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_addr.columns = ['i94addr','state']\n",
    "    df_addr['i94addr'] = clean_field(df_addr, 'i94addr', r'\\'([^\\']+)\\'')\n",
    "    df_addr['state'] = clean_field(df_addr, 'state', r'\\'([^\\']+)\\'')\n",
    "    \n",
    "    df_visa = pd.DataFrame(lines[1046:1049])\n",
    "    df_visa = df_visa[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_visa.columns = ['i94visa','visa']\n",
    "    df_visa['visa'] = clean_field(df_visa, 'visa', r'([^\\']+)\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5748522.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20579.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.498180e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5748523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497969e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5748524.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497975e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5748525.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497325e+10</td>\n",
       "      <td>00028</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5748526.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.501355e+10</td>\n",
       "      <td>00002</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5748527.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20576.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>GUZ</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>UA</td>\n",
       "      <td>9.493829e+10</td>\n",
       "      <td>01215</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5748528.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20575.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>GUZ</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.501810e+10</td>\n",
       "      <td>00472</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5748529.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VA</td>\n",
       "      <td>20596.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>PNM</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.492490e+10</td>\n",
       "      <td>00488</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5748530.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>PNM</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.492648e+10</td>\n",
       "      <td>00302</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5748531.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>PNM</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.492629e+10</td>\n",
       "      <td>00302</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0   5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1   5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2   5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3   5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4   5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "5   5748522.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "6   5748523.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "7   5748524.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "8   5748525.0  2016.0     4.0   245.0   464.0     HOU  20574.0      1.0   \n",
       "9   5748526.0  2016.0     4.0   245.0   464.0     LOS  20574.0      1.0   \n",
       "10  5748527.0  2016.0     4.0   245.0   504.0     NEW  20574.0      1.0   \n",
       "11  5748528.0  2016.0     4.0   245.0   504.0     LOS  20574.0      1.0   \n",
       "12  5748529.0  2016.0     4.0   245.0   504.0     WAS  20574.0      1.0   \n",
       "13  5748530.0  2016.0     4.0   245.0   504.0     LOS  20574.0      1.0   \n",
       "14  5748531.0  2016.0     4.0   245.0   504.0     LOS  20574.0      1.0   \n",
       "\n",
       "   i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0       CA  20582.0    40.0      1.0    1.0  20160430      SYD  None       G   \n",
       "1       NV  20591.0    32.0      1.0    1.0  20160430      SYD  None       G   \n",
       "2       WA  20582.0    29.0      1.0    1.0  20160430      SYD  None       G   \n",
       "3       WA  20588.0    29.0      1.0    1.0  20160430      SYD  None       G   \n",
       "4       WA  20588.0    28.0      1.0    1.0  20160430      SYD  None       G   \n",
       "5       HI  20579.0    57.0      2.0    1.0  20160430      ACK  None       G   \n",
       "6       HI  20586.0    66.0      2.0    1.0  20160430      ACK  None       G   \n",
       "7       HI  20586.0    41.0      2.0    1.0  20160430      ACK  None       G   \n",
       "8       FL  20581.0    27.0      2.0    1.0  20160430      ACK  None       G   \n",
       "9       CA  20581.0    26.0      2.0    1.0  20160430      ACK  None       G   \n",
       "10      MA  20576.0    44.0      2.0    1.0  20160430      GUZ  None       G   \n",
       "11    None  20575.0    39.0      2.0    1.0  20160430      GUZ  None       G   \n",
       "12      VA  20596.0    38.0      2.0    1.0  20160430      PNM  None       G   \n",
       "13      CA  20577.0    56.0      2.0    1.0  20160430      PNM  None       G   \n",
       "14      CA  20577.0    38.0      2.0    1.0  20160430      PNM  None       G   \n",
       "\n",
       "   entdepd entdepu matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0        O    None       M   1976.0  10292016      F   None      QF   \n",
       "1        O    None       M   1984.0  10292016      F   None      VA   \n",
       "2        O    None       M   1987.0  10292016      M   None      DL   \n",
       "3        O    None       M   1987.0  10292016      F   None      DL   \n",
       "4        O    None       M   1988.0  10292016      M   None      DL   \n",
       "5        O    None       M   1959.0  10292016      M   None      NZ   \n",
       "6        O    None       M   1950.0  10292016      F   None      NZ   \n",
       "7        O    None       M   1975.0  10292016      F   None      NZ   \n",
       "8        O    None       M   1989.0  10292016      M   None      NZ   \n",
       "9        O    None       M   1990.0  10292016      F   None      NZ   \n",
       "10       O    None       M   1972.0  10292016      M   None      UA   \n",
       "11       O    None       M   1977.0  10292016      M   None      CM   \n",
       "12       O    None       M   1978.0  10292016      M   None      CM   \n",
       "13       O    None       M   1960.0  10292016      F   None      CM   \n",
       "14       O    None       M   1978.0  10282016      M   None      CM   \n",
       "\n",
       "          admnum  fltno visatype  \n",
       "0   9.495387e+10  00011       B1  \n",
       "1   9.495562e+10  00007       B1  \n",
       "2   9.495641e+10  00040       B1  \n",
       "3   9.495645e+10  00040       B1  \n",
       "4   9.495639e+10  00040       B1  \n",
       "5   9.498180e+10  00010       B2  \n",
       "6   9.497969e+10  00010       B2  \n",
       "7   9.497975e+10  00010       B2  \n",
       "8   9.497325e+10  00028       B2  \n",
       "9   9.501355e+10  00002       B2  \n",
       "10  9.493829e+10  01215       B2  \n",
       "11  9.501810e+10  00472       B2  \n",
       "12  9.492490e+10  00488       B2  \n",
       "13  9.492648e+10  00302       B2  \n",
       "14  9.492629e+10  00302       B2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df_sas.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sas.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['occup', 'entdepu', 'insnum']\n"
     ]
    }
   ],
   "source": [
    "# Count the relative number of null values \n",
    "df_sas_total_rows = df_sas.count()\n",
    "df_sas_nulls = df_sas.select([(count(when(isnan(c) | col(c).isNull(), c))/df_sas_total_rows).alias(c) for c in df_sas.columns]).toPandas()\n",
    "\n",
    "# Drop columns with over 90% null values. \n",
    "# Note: This step is for demonstration purposes; in a real project I would leave\n",
    "# this decision to a data scientist.\n",
    "empty_cols = []\n",
    "for c in df_sas_nulls.columns:\n",
    "    if df_sas_nulls[c][0] > 0.9:\n",
    "        empty_cols.append(c)\n",
    "print(empty_cols)\n",
    "df_sas_clean_a = df_sas.drop(*empty_cols)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with duplicate ids\n",
    "df_sas_clean_b = df_sas_clean_a.dropna(how='all', subset=['cicid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert double columns to the original format (integer)\n",
    "df_sas_clean_c = df_sas_clean_b.\\\n",
    "withColumn(\"cicid\", df_sas_clean_b[\"cicid\"].cast('integer')).\\\n",
    "withColumn(\"i94yr\", df_sas_clean_b[\"i94yr\"].cast('integer')).\\\n",
    "withColumn(\"i94mon\", df_sas_clean_b[\"i94mon\"].cast('integer')).\\\n",
    "withColumn(\"i94cit\", df_sas_clean_b[\"i94cit\"].cast('integer')).\\\n",
    "withColumn(\"i94res\", df_sas_clean_b[\"i94res\"].cast('integer')).\\\n",
    "withColumn(\"arrdate\", df_sas_clean_b[\"arrdate\"].cast('integer')).\\\n",
    "withColumn(\"i94mode\", df_sas_clean_b[\"i94mode\"].cast('integer')).\\\n",
    "withColumn(\"i94bir\", df_sas_clean_b[\"i94bir\"].cast('integer')).\\\n",
    "withColumn(\"count\", df_sas_clean_b[\"count\"].cast('integer')).\\\n",
    "withColumn(\"i94visa\", df_sas_clean_b[\"i94visa\"].cast('integer')).\\\n",
    "withColumn(\"depdate\", df_sas_clean_b[\"depdate\"].cast('integer')).\\\n",
    "withColumn(\"biryear\", df_sas_clean_b[\"biryear\"].cast('integer')).\\\n",
    "withColumn(\"admnum\", df_sas_clean_b[\"admnum\"].cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert SAS date format to datetime:\n",
    "def date_add_(days):\n",
    "    date = datetime.strptime('1960-01-01', \"%Y-%m-%d\")\n",
    "    return date + timedelta(days)\n",
    "\n",
    "date_add_udf = f.udf(date_add_, t.DateType())\n",
    "\n",
    "df_sas_clean_d = df_sas_clean_c.withColumn('arrdate', date_add_udf('arrdate'))\\\n",
    "    .withColumn('depdate', date_add_udf('depdate'))\n",
    "\n",
    "# Drop year and mon columns\n",
    "df_sas_clean_e = df_sas_clean_d.drop('i94yr','i94mon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I have decided against keeping year and month columns (or even generating an additional day column), since we don't have weather data for these dates available, and hence a direct join would not make much sense. Instead, I leave it up to the data scientist on the receiving end of the data to process the date values and join them as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the weather and cyntl data, the country column is capitalized \n",
    "# to enable joins. I also convert the weather date string to datetime format.\n",
    "df_weather.columns=['date','average_temperature','average_temperature_uncertainty','country']\n",
    "df_weather['country'] = df_weather['country'].str.upper().astype(str)\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
    "df_weather=df_weather[df_weather['average_temperature'].notnull()]\n",
    "\n",
    "df_cntyl['country'] = df_cntyl['country'].str.upper().astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The demographic column names have many spaces and capitalization, so I adjust them to be DWH-friendly\n",
    "df_demo.columns=['city', 'state', 'median_age', 'male_population', 'female_population',\n",
    "       'total_population', 'number_of_veterans', 'foreign_born',\n",
    "       'average_household_size', 'state_code', 'race', 'count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "\n",
    "Here, I build the data pipelines to create the data model. We also define a testing function to perform some basic data quality checks on a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_quality_check(df):\n",
    "    \n",
    "    if(df.index.is_unique):\n",
    "        print(\"The dataframe has a unique index.\")\n",
    "    else:\n",
    "        print(\"Warning: The dataframe does not have a unique index.\")\n",
    "    \n",
    "    col_summary = dict()\n",
    "    for c in df.columns:\n",
    "        col_attributes = dict()\n",
    "        col_attributes['dtype'] = df[c].dtype\n",
    "        col_attributes['count'] = df[c].count()\n",
    "        col_attributes['count_null'] = df[c].size - col_attributes['count']\n",
    "        col_attributes['unique_values'] = df[c].nunique()\n",
    "    \n",
    "        col_summary[c] = col_attributes\n",
    "    return pd.DataFrame(col_summary).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immigration data\n",
    "\n",
    "With the cleanups we already did, the immigration data should actually be fine as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration_dwh = df_sas_clean_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather data: augment weather data with cntyl code\n",
    "\n",
    "In order to be able to join the weather data to the immigration data, the cntyl country code needs to be available in the weather data. This is done via a join on the country field. Ideally, this join would be fuzzy, but for now I will just perform a rigid join.\n",
    "\n",
    "We leave the actual aggreagation of weather data over time to the data scientist. This implies that country names will have multiple appearances, and hence cannot be used as an index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_dwh = pd.merge(left=df_weather, right=df_cntyl, \n",
    "                          left_on='country', right_on='country',\n",
    "                          how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "      <th>country</th>\n",
       "      <th>i94cntyl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>4.384</td>\n",
       "      <td>2.294</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>1.530</td>\n",
       "      <td>4.680</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>6.702</td>\n",
       "      <td>1.789</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>11.609</td>\n",
       "      <td>1.577</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>15.342</td>\n",
       "      <td>1.410</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  average_temperature  average_temperature_uncertainty country  \\\n",
       "0 1743-11-01                4.384                            2.294   ÅLAND   \n",
       "1 1744-04-01                1.530                            4.680   ÅLAND   \n",
       "2 1744-05-01                6.702                            1.789   ÅLAND   \n",
       "3 1744-06-01               11.609                            1.577   ÅLAND   \n",
       "4 1744-07-01               15.342                            1.410   ÅLAND   \n",
       "\n",
       "   i94cntyl  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_dwh.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep countries that are in the imigration data\n",
    "i94cntyl_in_sas = list(set(df_immigration_dwh.select(\"i94cit\").distinct().toPandas()['i94cit'] \\\n",
    "+ df_immigration_dwh.select(\"i94res\").distinct().toPandas()['i94res']))\n",
    "i94cntyl_in_sas = [int(x) for x in i94cntyl_in_sas if str(x) != 'nan']\n",
    "\n",
    "df_weather_dwh = df_weather_dwh[df_weather_dwh['i94cntyl'].notnull()]\n",
    "df_weather_dwh = df_weather_dwh[df_weather_dwh['i94cntyl'].isin(i94cntyl_in_sas)]\n",
    "df_weather_dwh = df_weather_dwh.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "      <th>country</th>\n",
       "      <th>i94cntyl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1824-01-01</td>\n",
       "      <td>25.146</td>\n",
       "      <td>0.874</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1824-02-01</td>\n",
       "      <td>24.806</td>\n",
       "      <td>2.374</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1824-03-01</td>\n",
       "      <td>25.318</td>\n",
       "      <td>1.090</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1824-04-01</td>\n",
       "      <td>26.430</td>\n",
       "      <td>2.173</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1824-05-01</td>\n",
       "      <td>26.553</td>\n",
       "      <td>1.217</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  average_temperature  average_temperature_uncertainty   country  \\\n",
       "0 1824-01-01               25.146                            0.874  BARBADOS   \n",
       "1 1824-02-01               24.806                            2.374  BARBADOS   \n",
       "2 1824-03-01               25.318                            1.090  BARBADOS   \n",
       "3 1824-04-01               26.430                            2.173  BARBADOS   \n",
       "4 1824-05-01               26.553                            1.217  BARBADOS   \n",
       "\n",
       "   i94cntyl  \n",
       "0     513.0  \n",
       "1     513.0  \n",
       "2     513.0  \n",
       "3     513.0  \n",
       "4     513.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_dwh.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has a unique index.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count_null</th>\n",
       "      <th>dtype</th>\n",
       "      <th>unique_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>40018</td>\n",
       "      <td>0</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>2457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_temperature</th>\n",
       "      <td>40018</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>16448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "      <td>40018</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>2726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>40018</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94cntyl</th>\n",
       "      <td>40018</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count count_null           dtype  \\\n",
       "date                             40018          0  datetime64[ns]   \n",
       "average_temperature              40018          0         float64   \n",
       "average_temperature_uncertainty  40018          0         float64   \n",
       "country                          40018          0          object   \n",
       "i94cntyl                         40018          0         float64   \n",
       "\n",
       "                                unique_values  \n",
       "date                                     2457  \n",
       "average_temperature                     16448  \n",
       "average_temperature_uncertainty          2726  \n",
       "country                                    20  \n",
       "i94cntyl                                   20  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_quality_check(df_weather_dwh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### State data: aggregate demographic data on state level\n",
    "\n",
    "We aggregate the available numeric data on a city level for each state. Since we don't have access to total state demographics in this data set, we express the male population, female population, veteran number and foreign born number as fractions of total pupolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_dwh = df_demo[['state_code', 'state']].drop_duplicates().set_index('state_code')\\\n",
    ".join(df_demo.groupby(['state_code'])['male_population', 'female_population',\\\n",
    "                                      'total_population', 'number_of_veterans', 'foreign_born'].agg('sum'))\\\n",
    ".join(df_demo.groupby(['state_code'])['median_age', 'average_household_size'].agg('median'))\n",
    "\n",
    "df_demo_dwh['male_population'] = df_demo_dwh['male_population']/df_demo_dwh['total_population']\n",
    "df_demo_dwh['female_population'] = df_demo_dwh['female_population']/df_demo_dwh['total_population']\n",
    "df_demo_dwh['number_of_veterans'] = df_demo_dwh['number_of_veterans']/df_demo_dwh['total_population']\n",
    "df_demo_dwh['foreign_born'] = df_demo_dwh['foreign_born']/df_demo_dwh['total_population']\n",
    "\n",
    "df_demo_dwh = df_demo_dwh.drop(['total_population'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>median_age</th>\n",
       "      <th>average_household_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>0.478574</td>\n",
       "      <td>0.521426</td>\n",
       "      <td>0.048885</td>\n",
       "      <td>0.175131</td>\n",
       "      <td>35.9</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>0.484253</td>\n",
       "      <td>0.515747</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>0.257458</td>\n",
       "      <td>34.9</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.474154</td>\n",
       "      <td>0.525846</td>\n",
       "      <td>0.068347</td>\n",
       "      <td>0.048911</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>California</td>\n",
       "      <td>0.494601</td>\n",
       "      <td>0.505399</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>0.300214</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>0.493871</td>\n",
       "      <td>0.506129</td>\n",
       "      <td>0.021156</td>\n",
       "      <td>0.335845</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    state  male_population  female_population  \\\n",
       "state_code                                                      \n",
       "MD               Maryland         0.478574           0.521426   \n",
       "MA          Massachusetts         0.484253           0.515747   \n",
       "AL                Alabama         0.474154           0.525846   \n",
       "CA             California         0.494601           0.505399   \n",
       "NJ             New Jersey         0.493871           0.506129   \n",
       "\n",
       "            number_of_veterans  foreign_born  median_age  \\\n",
       "state_code                                                 \n",
       "MD                    0.048885      0.175131        35.9   \n",
       "MA                    0.032929      0.257458        34.9   \n",
       "AL                    0.068347      0.048911        38.0   \n",
       "CA                    0.037402      0.300214        35.8   \n",
       "NJ                    0.021156      0.335845        34.6   \n",
       "\n",
       "            average_household_size  \n",
       "state_code                          \n",
       "MD                            2.64  \n",
       "MA                            2.43  \n",
       "AL                            2.41  \n",
       "CA                            3.06  \n",
       "NJ                            2.85  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_dwh.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has a unique index.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count_null</th>\n",
       "      <th>dtype</th>\n",
       "      <th>unique_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_population</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_population</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_veterans</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreign_born</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_age</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_household_size</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>float64</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count count_null    dtype unique_values\n",
       "state                     49          0   object            49\n",
       "male_population           49          0  float64            49\n",
       "female_population         49          0  float64            49\n",
       "number_of_veterans        49          0  float64            49\n",
       "foreign_born              49          0  float64            49\n",
       "median_age                49          0  float64            39\n",
       "average_household_size    48          1  float64            41"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_quality_check(df_demo_dwh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the data above, we can also extract the \"race distribution\" of each state in a similar fashion. This table acts as an additinal dimension table for each state code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_race_dwh = pd.DataFrame(df_demo.groupby(['state_code', 'race'])['count'].agg('sum'))\\\n",
    ".join(df_demo.groupby(['state_code'])['count'].agg('sum'), rsuffix='_total')\n",
    "\n",
    "df_demo_race_dwh['fraction']=df_demo_race_dwh['count']/df_demo_race_dwh['count_total']\n",
    "df_demo_race_dwh = pd.DataFrame(df_demo_race_dwh['fraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fraction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AK</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <td>0.108078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>0.109524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African-American</th>\n",
       "      <td>0.068724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <td>0.081079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.632595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AL</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <td>0.007375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>0.026245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African-American</th>\n",
       "      <td>0.475360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <td>0.035864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.455155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              fraction\n",
       "state_code race                                       \n",
       "AK         American Indian and Alaska Native  0.108078\n",
       "           Asian                              0.109524\n",
       "           Black or African-American          0.068724\n",
       "           Hispanic or Latino                 0.081079\n",
       "           White                              0.632595\n",
       "AL         American Indian and Alaska Native  0.007375\n",
       "           Asian                              0.026245\n",
       "           Black or African-American          0.475360\n",
       "           Hispanic or Latino                 0.035864\n",
       "           White                              0.455155"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_race_dwh.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has a unique index.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count_null</th>\n",
       "      <th>dtype</th>\n",
       "      <th>unique_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fraction</th>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count count_null    dtype unique_values\n",
       "fraction   243          0  float64           243"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_quality_check(df_demo_race_dwh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### State data from sas: not used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data only contains information which is already available in the state data above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94addr</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  i94addr       state\n",
       "0      AL     ALABAMA\n",
       "1      AK      ALASKA\n",
       "2      AZ     ARIZONA\n",
       "3      AR    ARKANSAS\n",
       "4      CA  CALIFORNIA"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_addr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mode data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mode data can be taken as-is with the correct index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode_dwh=df_mode.set_index('i94mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94mode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOT REPORTED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mode\n",
       "i94mode              \n",
       "1                 AIR\n",
       "2                 SEA\n",
       "3                LAND\n",
       "9        NOT REPORTED"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode_dwh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visa data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visa data can be taken as-is with the correct index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visa_dwh = df_visa.set_index('i94visa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94visa</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             visa\n",
       "i94visa          \n",
       "   1     BUSINESS\n",
       "   2     PLEASURE\n",
       "   3      STUDENT"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visa_dwh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Airport data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we extracted df_port from the sas data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94port</th>\n",
       "      <th>port</th>\n",
       "      <th>addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  i94port                      port addr\n",
       "0     ALC                     ALCAN   AK\n",
       "1     ANC                 ANCHORAGE   AK\n",
       "2     BAR  BAKER AAF - BAKER ISLAND   AK\n",
       "3     DAC             DALTONS CACHE   AK\n",
       "4     PIZ    DEW STATION PT LAY DEW   AK"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can attempt to combine this information with the available airport information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport_dwh = pd.merge(left=df_port, right=df_airport, \n",
    "                          left_on='i94port', right_on='ident',\n",
    "                          how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The join is acctually sucesfful in some occasions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94port</th>\n",
       "      <th>port</th>\n",
       "      <th>addr</th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5KE</td>\n",
       "      <td>KETCHIKAN</td>\n",
       "      <td>AK</td>\n",
       "      <td>5KE</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Ketchikan Harbor Seaplane Base</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Ketchikan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WFB</td>\n",
       "      <td>5KE</td>\n",
       "      <td>-131.677002, 55.349899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MOS</td>\n",
       "      <td>MOSES POINT INTERMEDIATE</td>\n",
       "      <td>AK</td>\n",
       "      <td>MOS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Moses Point Airport</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Elim</td>\n",
       "      <td>MOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOS</td>\n",
       "      <td>-162.0570068359375, 64.69819641113281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NOM</td>\n",
       "      <td>NOM</td>\n",
       "      <td>AK</td>\n",
       "      <td>NOM</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nomad River Airport</td>\n",
       "      <td>305.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>PG</td>\n",
       "      <td>PG-WPD</td>\n",
       "      <td>Nomad River</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOM</td>\n",
       "      <td>NDR</td>\n",
       "      <td>142.234166667, -6.294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94port                      port addr ident           type  \\\n",
       "11     5KE                 KETCHIKAN   AK   5KE  seaplane_base   \n",
       "13     MOS  MOSES POINT INTERMEDIATE   AK   MOS  small_airport   \n",
       "15     NOM                       NOM   AK   NOM  small_airport   \n",
       "\n",
       "                              name  elevation_ft continent iso_country  \\\n",
       "11  Ketchikan Harbor Seaplane Base           NaN       NaN          US   \n",
       "13             Moses Point Airport          14.0       NaN          US   \n",
       "15             Nomad River Airport         305.0        OC          PG   \n",
       "\n",
       "   iso_region municipality gps_code iata_code local_code  \\\n",
       "11      US-AK    Ketchikan      NaN       WFB        5KE   \n",
       "13      US-AK         Elim      MOS       NaN        MOS   \n",
       "15     PG-WPD  Nomad River      NaN       NOM        NDR   \n",
       "\n",
       "                              coordinates  \n",
       "11                 -131.677002, 55.349899  \n",
       "13  -162.0570068359375, 64.69819641113281  \n",
       "15                  142.234166667, -6.294  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_dwh[df_airport_dwh['type'].notnull()].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has a unique index.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count_null</th>\n",
       "      <th>dtype</th>\n",
       "      <th>unique_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i94port</th>\n",
       "      <td>660</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>port</th>\n",
       "      <td>660</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr</th>\n",
       "      <td>583</td>\n",
       "      <td>77</td>\n",
       "      <td>object</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ident</th>\n",
       "      <td>37</td>\n",
       "      <td>623</td>\n",
       "      <td>object</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>37</td>\n",
       "      <td>623</td>\n",
       "      <td>object</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>37</td>\n",
       "      <td>623</td>\n",
       "      <td>object</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation_ft</th>\n",
       "      <td>30</td>\n",
       "      <td>630</td>\n",
       "      <td>float64</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continent</th>\n",
       "      <td>17</td>\n",
       "      <td>643</td>\n",
       "      <td>object</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iso_country</th>\n",
       "      <td>37</td>\n",
       "      <td>623</td>\n",
       "      <td>object</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iso_region</th>\n",
       "      <td>37</td>\n",
       "      <td>623</td>\n",
       "      <td>object</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>municipality</th>\n",
       "      <td>33</td>\n",
       "      <td>627</td>\n",
       "      <td>object</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gps_code</th>\n",
       "      <td>16</td>\n",
       "      <td>644</td>\n",
       "      <td>object</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iata_code</th>\n",
       "      <td>28</td>\n",
       "      <td>632</td>\n",
       "      <td>object</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_code</th>\n",
       "      <td>18</td>\n",
       "      <td>642</td>\n",
       "      <td>object</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinates</th>\n",
       "      <td>37</td>\n",
       "      <td>623</td>\n",
       "      <td>object</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count count_null    dtype unique_values\n",
       "i94port        660          0   object           660\n",
       "port           660          0   object           634\n",
       "addr           583         77   object           112\n",
       "ident           37        623   object            37\n",
       "type            37        623   object             4\n",
       "name            37        623   object            37\n",
       "elevation_ft    30        630  float64            28\n",
       "continent       17        643   object             5\n",
       "iso_country     37        623   object            12\n",
       "iso_region      37        623   object            22\n",
       "municipality    33        627   object            33\n",
       "gps_code        16        644   object            16\n",
       "iata_code       28        632   object            28\n",
       "local_code      18        642   object            18\n",
       "coordinates     37        623   object            37"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_quality_check(df_airport_dwh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an additional check: The iso_region field from df_airport should match with the addr field from df_port. Let us check the cases where this is _not_ true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94port</th>\n",
       "      <th>port</th>\n",
       "      <th>addr</th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>iso_region_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NOM</td>\n",
       "      <td>NOM</td>\n",
       "      <td>AK</td>\n",
       "      <td>NOM</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nomad River Airport</td>\n",
       "      <td>305.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>PG</td>\n",
       "      <td>WPD</td>\n",
       "      <td>Nomad River</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOM</td>\n",
       "      <td>NDR</td>\n",
       "      <td>142.234166667, -6.294</td>\n",
       "      <td>WPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MAP</td>\n",
       "      <td>MARIPOSA AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAP</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Mamai Airport</td>\n",
       "      <td>90.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>PG</td>\n",
       "      <td>CPM</td>\n",
       "      <td>Mamai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.519166667, -10.290833333299998</td>\n",
       "      <td>CPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SAS</td>\n",
       "      <td>SASABE</td>\n",
       "      <td>AZ</td>\n",
       "      <td>SAS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Salton Sea Airport</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "      <td>Salton City</td>\n",
       "      <td>KSAS</td>\n",
       "      <td>SAS</td>\n",
       "      <td>SAS</td>\n",
       "      <td>-115.952003479, 33.2414016724</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>DVD</td>\n",
       "      <td>DOVER-AFB</td>\n",
       "      <td>DE</td>\n",
       "      <td>DVD</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Andavadoaka Airport</td>\n",
       "      <td>30.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>MG</td>\n",
       "      <td>U</td>\n",
       "      <td>Andavadoaka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.259573, -22.06608</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>LKC</td>\n",
       "      <td>LAKE CHARLES</td>\n",
       "      <td>LA</td>\n",
       "      <td>LKC</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lekana Airport</td>\n",
       "      <td>2634.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>CG</td>\n",
       "      <td>14</td>\n",
       "      <td>Lekana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LKC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.606, -2.313</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>HTM</td>\n",
       "      <td>HOULTON</td>\n",
       "      <td>ME</td>\n",
       "      <td>HTM</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Khatgal Airport</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>MN</td>\n",
       "      <td>041</td>\n",
       "      <td>Hatgal</td>\n",
       "      <td>ZMHG</td>\n",
       "      <td>HTM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.139532, 50.435988</td>\n",
       "      <td>041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>SRL</td>\n",
       "      <td>ST AURELIE</td>\n",
       "      <td>ME</td>\n",
       "      <td>SRL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Palo Verde Airport</td>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MX</td>\n",
       "      <td>BCS</td>\n",
       "      <td>Santa Rosalia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRL</td>\n",
       "      <td>CIB</td>\n",
       "      <td>-112.0985, 27.0927</td>\n",
       "      <td>BCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>SAG</td>\n",
       "      <td>SAGINAW</td>\n",
       "      <td>MI</td>\n",
       "      <td>SAG</td>\n",
       "      <td>closed</td>\n",
       "      <td>Sagwon Airport</td>\n",
       "      <td>650.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>Sagwon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-148.7114, 69.3596</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>WSB</td>\n",
       "      <td>WARROAD INTL</td>\n",
       "      <td>SPB, MN</td>\n",
       "      <td>WSB</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Steamboat Bay Seaplane Base</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>Steamboat Bay</td>\n",
       "      <td>WSB</td>\n",
       "      <td>WSB</td>\n",
       "      <td>WSB</td>\n",
       "      <td>-133.641998291, 55.5295982361</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>SWE</td>\n",
       "      <td>SWEETGTASS</td>\n",
       "      <td>MT</td>\n",
       "      <td>SWE</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Siwea Airport</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>PG</td>\n",
       "      <td>MPL</td>\n",
       "      <td>Siwea</td>\n",
       "      <td>AYEW</td>\n",
       "      <td>SWE</td>\n",
       "      <td>SIW</td>\n",
       "      <td>147.580833, -6.284639</td>\n",
       "      <td>MPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i94port          port     addr ident           type  \\\n",
       "15      NOM           NOM       AK   NOM  small_airport   \n",
       "28      MAP   MARIPOSA AZ      NaN   MAP  small_airport   \n",
       "34      SAS        SASABE       AZ   SAS  small_airport   \n",
       "78      DVD     DOVER-AFB       DE   DVD  small_airport   \n",
       "140     LKC  LAKE CHARLES       LA   LKC  small_airport   \n",
       "167     HTM       HOULTON       ME   HTM  small_airport   \n",
       "176     SRL    ST AURELIE       ME   SRL  small_airport   \n",
       "192     SAG       SAGINAW       MI   SAG         closed   \n",
       "217     WSB  WARROAD INTL  SPB, MN   WSB  seaplane_base   \n",
       "249     SWE    SWEETGTASS       MT   SWE  small_airport   \n",
       "\n",
       "                            name  elevation_ft continent iso_country  \\\n",
       "15           Nomad River Airport         305.0        OC          PG   \n",
       "28                 Mamai Airport          90.0        OC          PG   \n",
       "34            Salton Sea Airport         -84.0       NaN          US   \n",
       "78           Andavadoaka Airport          30.0        AF          MG   \n",
       "140               Lekana Airport        2634.0        AF          CG   \n",
       "167              Khatgal Airport        5500.0        AS          MN   \n",
       "176           Palo Verde Airport         127.0       NaN          MX   \n",
       "192               Sagwon Airport         650.0       NaN          US   \n",
       "217  Steamboat Bay Seaplane Base           NaN       NaN          US   \n",
       "249                Siwea Airport        5960.0        OC          PG   \n",
       "\n",
       "    iso_region   municipality gps_code iata_code local_code  \\\n",
       "15         WPD    Nomad River      NaN       NOM        NDR   \n",
       "28         CPM          Mamai      NaN       MAP        NaN   \n",
       "34          CA    Salton City     KSAS       SAS        SAS   \n",
       "78           U    Andavadoaka      NaN       DVD        NaN   \n",
       "140         14         Lekana      NaN       LKC        NaN   \n",
       "167        041         Hatgal     ZMHG       HTM        NaN   \n",
       "176        BCS  Santa Rosalia      NaN       SRL        CIB   \n",
       "192         AK         Sagwon      NaN       NaN        NaN   \n",
       "217         AK  Steamboat Bay      WSB       WSB        WSB   \n",
       "249        MPL          Siwea     AYEW       SWE        SIW   \n",
       "\n",
       "                            coordinates iso_region_state  \n",
       "15                142.234166667, -6.294              WPD  \n",
       "28   149.519166667, -10.290833333299998              CPM  \n",
       "34        -115.952003479, 33.2414016724               CA  \n",
       "78                 43.259573, -22.06608                U  \n",
       "140                      14.606, -2.313               14  \n",
       "167               100.139532, 50.435988              041  \n",
       "176                  -112.0985, 27.0927              BCS  \n",
       "192                  -148.7114, 69.3596               AK  \n",
       "217       -133.641998291, 55.5295982361               AK  \n",
       "249               147.580833, -6.284639              MPL  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_dwh['iso_region_state'] = clean_field(df_airport_dwh, 'iso_region', r'-([^-]+)')\n",
    "df_airport_dwh_outliers = df_airport_dwh[\\\n",
    "    (df_airport_dwh['ident'].notnull())\\\n",
    "    & (df_airport_dwh['iso_region_state'] != df_airport_dwh['addr'])]\n",
    "\n",
    "print(len(df_airport_dwh_outliers))\n",
    "df_airport_dwh_outliers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these are not even in the US, which clearly indicates a false join. This makes it hard to trust the data we generated with the join. We should _at least_ remove these case, even though they will leave very little data to work with. I will leave this as an option question an simple flag the data with the improper join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport_dwh['false_join'] = df_airport_dwh.index.isin(df_airport_dwh_outliers.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **bold** values link to other fact/dimension tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df_immigration_dwh\n",
    "\n",
    "This is the fact table with the immigration data. \n",
    "\n",
    "| field | type | description | origin |\n",
    "| --- | --- | --- | --- |\n",
    "| cicid | int | unique id | original parquet/sas files\n",
    "| **i94cit** | int | country code (birth) | original parquet/sas files\n",
    "| **i94res** | int | country code (residence) | original parquet/sas files\n",
    "| i94port | string | arrival airport | original parquet/sas files\n",
    "| arrdate | date | arrival date | original parquet/sas files\n",
    "| i94mode | int | mode of transportation | original parquet/sas files\n",
    "| i94addr | string | arrival state code | original parquet/sas files\n",
    "| depdate | int | departure date | original parquet/sas files\n",
    "| i94bir | int | age of respondent in years | original parquet/sas files\n",
    "| **i94visa** | int | visa type | original parquet/sas files\n",
    "| count | int | summary statistics | original parquet/sas files\n",
    "| dtadfile | string | character date field | original parquet/sas files\n",
    "| visapost | string | Department of State where where Visa was issued | original parquet/sas files\n",
    "| entdepa | string | Arrival Flag | original parquet/sas files\n",
    "| entdepd | string | Departure Flag | original parquet/sas files\n",
    "| matflag | string | Match flag | original parquet/sas files\n",
    "| biryear | int | 4 digit year of birth | original parquet/sas files\n",
    "| dtaddto | string | character date field | original parquet/sas files\n",
    "| gender | string | Non-immigrant sex | original parquet/sas files\n",
    "| airline | string | Airline used to arrive in US | original parquet/sas files\n",
    "| admnum | int | Admission number | original parquet/sas files\n",
    "| fltno | string | Flight number | original parquet/sas files\n",
    "| **visatype** | string | class of admission | original parquet/sas files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df_weather_dwh\n",
    "\n",
    "This is a fact table with weather data by country and date. \n",
    "\n",
    "| field | type | description | origin |\n",
    "| --- | --- | --- | --- |\n",
    "| index | int | unique id | generated |\n",
    "| date | date | date of record | weather data |\n",
    "| average_temperature | numeric |average temperature |weather data |\n",
    "| average_temperature_uncertainty |  numeric | average temperature uncertainty  | weather data |\n",
    "| country | string | country | weather data |\n",
    "| **i94cntyl** | int | cntyl country code | SAS description via join | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df_demo_dwh\n",
    "\n",
    "This is a dimension table that provides demographic data for the states in the us.\n",
    "\n",
    "| field | type | description | origin |\n",
    "| --- | --- | --- | --- |\n",
    "| **state_code** | string | us state code | demographic data |\n",
    "| state | string | us state | demographic data |\n",
    "| male_population | numeric | fraction of males |demographic data |\n",
    "| female_population | numeric | fraction of females |demographic data |\n",
    "| number_of_veterans | numeric | fraction of veterans | demographic data |\n",
    "| foreign_born | numeric | fraction of foreign borns | demographic data |\n",
    "| median_age | numeric | median age | demographic data |\n",
    "| average_household_size | numeric | average household size | demographic data |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: integer (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration_dwh.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
