{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "## Data Engineering Capstone Project\n",
    "\n",
    "### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to its size, I process the \n",
    "df_sas = spark.read.parquet(\"sas_data\")\n",
    "df_airport = pd.read_csv(\"data/airport-codes_csv.csv\")\n",
    "df_demo = pd.read_csv(\"data/us-cities-demographics.csv\", sep=';')\n",
    "df_weather = pd.read_csv(\"temperature_data/GlobalLandTemperaturesByCountry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    \n",
    "    def clean_field(df, col, regex):\n",
    "        df[col] = df[col].str.extract(regex)\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col] = df[col].str.upper()\n",
    "        return df[col]\n",
    "    \n",
    "    lines=f.readlines()\n",
    "    \n",
    "    df_cntyl = pd.DataFrame(lines[9:297])\n",
    "    df_cntyl = df_cntyl[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_cntyl.columns = ['i94cntyl','country']\n",
    "    df_cntyl['country'] = clean_field(df_cntyl, 'country', r'\\'([^\\']+)\\'')\n",
    "    df_cntyl['i94cntyl'] = df_cntyl['i94cntyl'].astype(int)\n",
    "    \n",
    "    df_port = pd.DataFrame(lines[302:962])\n",
    "    df_port = df_port[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_port_comma_split = df_port[1].str.split(\",\", n=1, expand= True)\n",
    "    df_port[1] = df_port_comma_split[0]\n",
    "    df_port[2] = df_port_comma_split[1]\n",
    "    df_port.columns = ['i94port','port','addr']\n",
    "    df_port['i94port'] = clean_field(df_port, 'i94port', r'\\'([^\\']+)\\'')\n",
    "    df_port['port'] = clean_field(df_port, 'port', r'\\'([^\\']+)')\n",
    "    df_port['addr'] = clean_field(df_port, 'addr', r'([^\\']+)\\'')\n",
    "  \n",
    "    df_mode = pd.DataFrame(lines[972:976])\n",
    "    df_mode = df_mode[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_mode.columns = ['i94mode','mode']\n",
    "    df_mode['mode'] = clean_field(df_mode, 'mode', r'\\'([^\\']+)\\'')\n",
    "    df_mode['i94mode'] = clean_field(df_mode, 'i94mode', r'\\s+([^\\']+)')\n",
    "    \n",
    "    df_addr = pd.DataFrame(lines[981:1036])\n",
    "    df_addr = df_addr[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_addr.columns = ['i94addr','state']\n",
    "    df_addr['i94addr'] = clean_field(df_addr, 'i94addr', r'\\'([^\\']+)\\'')\n",
    "    df_addr['state'] = clean_field(df_addr, 'state', r'\\'([^\\']+)\\'')\n",
    "    \n",
    "    df_visa = pd.DataFrame(lines[1046:1049])\n",
    "    df_visa = df_visa[0].str.split(\"=\", n=1, expand= True)\n",
    "    df_visa.columns = ['i94visa','visa']\n",
    "    df_visa['visa'] = clean_field(df_visa, 'visa', r'([^\\']+)\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5748522.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20579.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.498180e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5748523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497969e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5748524.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497975e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5748525.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497325e+10</td>\n",
       "      <td>00028</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5748526.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>ACK</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.501355e+10</td>\n",
       "      <td>00002</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5748527.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20576.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>GUZ</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>UA</td>\n",
       "      <td>9.493829e+10</td>\n",
       "      <td>01215</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5748528.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20575.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>GUZ</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.501810e+10</td>\n",
       "      <td>00472</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5748529.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VA</td>\n",
       "      <td>20596.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>PNM</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.492490e+10</td>\n",
       "      <td>00488</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5748530.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>PNM</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.492648e+10</td>\n",
       "      <td>00302</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5748531.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>PNM</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.492629e+10</td>\n",
       "      <td>00302</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0   5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1   5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2   5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3   5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4   5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "5   5748522.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "6   5748523.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "7   5748524.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "8   5748525.0  2016.0     4.0   245.0   464.0     HOU  20574.0      1.0   \n",
       "9   5748526.0  2016.0     4.0   245.0   464.0     LOS  20574.0      1.0   \n",
       "10  5748527.0  2016.0     4.0   245.0   504.0     NEW  20574.0      1.0   \n",
       "11  5748528.0  2016.0     4.0   245.0   504.0     LOS  20574.0      1.0   \n",
       "12  5748529.0  2016.0     4.0   245.0   504.0     WAS  20574.0      1.0   \n",
       "13  5748530.0  2016.0     4.0   245.0   504.0     LOS  20574.0      1.0   \n",
       "14  5748531.0  2016.0     4.0   245.0   504.0     LOS  20574.0      1.0   \n",
       "\n",
       "   i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0       CA  20582.0    40.0      1.0    1.0  20160430      SYD  None       G   \n",
       "1       NV  20591.0    32.0      1.0    1.0  20160430      SYD  None       G   \n",
       "2       WA  20582.0    29.0      1.0    1.0  20160430      SYD  None       G   \n",
       "3       WA  20588.0    29.0      1.0    1.0  20160430      SYD  None       G   \n",
       "4       WA  20588.0    28.0      1.0    1.0  20160430      SYD  None       G   \n",
       "5       HI  20579.0    57.0      2.0    1.0  20160430      ACK  None       G   \n",
       "6       HI  20586.0    66.0      2.0    1.0  20160430      ACK  None       G   \n",
       "7       HI  20586.0    41.0      2.0    1.0  20160430      ACK  None       G   \n",
       "8       FL  20581.0    27.0      2.0    1.0  20160430      ACK  None       G   \n",
       "9       CA  20581.0    26.0      2.0    1.0  20160430      ACK  None       G   \n",
       "10      MA  20576.0    44.0      2.0    1.0  20160430      GUZ  None       G   \n",
       "11    None  20575.0    39.0      2.0    1.0  20160430      GUZ  None       G   \n",
       "12      VA  20596.0    38.0      2.0    1.0  20160430      PNM  None       G   \n",
       "13      CA  20577.0    56.0      2.0    1.0  20160430      PNM  None       G   \n",
       "14      CA  20577.0    38.0      2.0    1.0  20160430      PNM  None       G   \n",
       "\n",
       "   entdepd entdepu matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0        O    None       M   1976.0  10292016      F   None      QF   \n",
       "1        O    None       M   1984.0  10292016      F   None      VA   \n",
       "2        O    None       M   1987.0  10292016      M   None      DL   \n",
       "3        O    None       M   1987.0  10292016      F   None      DL   \n",
       "4        O    None       M   1988.0  10292016      M   None      DL   \n",
       "5        O    None       M   1959.0  10292016      M   None      NZ   \n",
       "6        O    None       M   1950.0  10292016      F   None      NZ   \n",
       "7        O    None       M   1975.0  10292016      F   None      NZ   \n",
       "8        O    None       M   1989.0  10292016      M   None      NZ   \n",
       "9        O    None       M   1990.0  10292016      F   None      NZ   \n",
       "10       O    None       M   1972.0  10292016      M   None      UA   \n",
       "11       O    None       M   1977.0  10292016      M   None      CM   \n",
       "12       O    None       M   1978.0  10292016      M   None      CM   \n",
       "13       O    None       M   1960.0  10292016      F   None      CM   \n",
       "14       O    None       M   1978.0  10282016      M   None      CM   \n",
       "\n",
       "          admnum  fltno visatype  \n",
       "0   9.495387e+10  00011       B1  \n",
       "1   9.495562e+10  00007       B1  \n",
       "2   9.495641e+10  00040       B1  \n",
       "3   9.495645e+10  00040       B1  \n",
       "4   9.495639e+10  00040       B1  \n",
       "5   9.498180e+10  00010       B2  \n",
       "6   9.497969e+10  00010       B2  \n",
       "7   9.497975e+10  00010       B2  \n",
       "8   9.497325e+10  00028       B2  \n",
       "9   9.501355e+10  00002       B2  \n",
       "10  9.493829e+10  01215       B2  \n",
       "11  9.501810e+10  00472       B2  \n",
       "12  9.492490e+10  00488       B2  \n",
       "13  9.492648e+10  00302       B2  \n",
       "14  9.492629e+10  00302       B2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df_sas.limit(15).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sas.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['occup', 'entdepu', 'insnum']\n"
     ]
    }
   ],
   "source": [
    "# Count the relative number of null values \n",
    "df_sas_total_rows = df_sas.count()\n",
    "df_sas_nulls = df_sas.select([(count(when(isnan(c) | col(c).isNull(), c))/df_sas_total_rows).alias(c) for c in df_sas.columns]).toPandas()\n",
    "\n",
    "# Drop columns with over 90% null values. \n",
    "# Note: This step is for demonstration purposes; in a real project I would leave\n",
    "# this decision to a data scientist.\n",
    "empty_cols = []\n",
    "for c in df_sas_nulls.columns:\n",
    "    if df_sas_nulls[c][0] > 0.9:\n",
    "        empty_cols.append(c)\n",
    "print(empty_cols)\n",
    "df_sas_clean_a = df_sas.drop(*empty_cols)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with duplicate ids\n",
    "df_sas_clean_b = df_sas_clean_a.dropna(how='all', subset=['cicid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert double columns to the original format (integer)\n",
    "df_sas_clean_c = df_sas_clean_b.\\\n",
    "withColumn(\"cicid\", df_sas_clean_b[\"cicid\"].cast('integer')).\\\n",
    "withColumn(\"i94yr\", df_sas_clean_b[\"i94yr\"].cast('integer')).\\\n",
    "withColumn(\"i94mon\", df_sas_clean_b[\"i94mon\"].cast('integer')).\\\n",
    "withColumn(\"i94cit\", df_sas_clean_b[\"i94cit\"].cast('integer')).\\\n",
    "withColumn(\"i94res\", df_sas_clean_b[\"i94res\"].cast('integer')).\\\n",
    "withColumn(\"arrdate\", df_sas_clean_b[\"arrdate\"].cast('integer')).\\\n",
    "withColumn(\"i94mode\", df_sas_clean_b[\"i94mode\"].cast('integer')).\\\n",
    "withColumn(\"i94bir\", df_sas_clean_b[\"i94bir\"].cast('integer')).\\\n",
    "withColumn(\"count\", df_sas_clean_b[\"count\"].cast('integer')).\\\n",
    "withColumn(\"i94visa\", df_sas_clean_b[\"i94visa\"].cast('integer')).\\\n",
    "withColumn(\"depdate\", df_sas_clean_b[\"depdate\"].cast('integer')).\\\n",
    "withColumn(\"biryear\", df_sas_clean_b[\"biryear\"].cast('integer')).\\\n",
    "withColumn(\"admnum\", df_sas_clean_b[\"admnum\"].cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert SAS date format to datetime:\n",
    "def date_add_(days):\n",
    "    date = datetime.strptime('1960-01-01', \"%Y-%m-%d\")\n",
    "    return date + timedelta(days)\n",
    "\n",
    "date_add_udf = f.udf(date_add_, t.DateType())\n",
    "\n",
    "df_sas_clean_d = df_sas_clean_c.withColumn('arrdate', date_add_udf('arrdate'))\n",
    "\n",
    "# Drop year and mon columns\n",
    "df_sas_clean_e = df_sas_clean_d.drop('i94year','i94mon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I have decided against keeping year and month columns (or even generating an additional day column), since we don't have weather data for these dates available, and hence a direct join would not make much sense. Instead, I leave it up to the data scientist on the receiving end of the data to process the date values and join them as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the weather and cyntl data, the country column is capitalized \n",
    "# to enable joins. I also convert the weather date string to datetime format.\n",
    "df_weather.columns=['date','average_temperature','average_temperature_uncertainty','country']\n",
    "df_weather['country'] = df_weather['country'].str.upper()\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
    "df_weather=df_weather[df_weather['average_temperature'].notnull()]\n",
    "\n",
    "df_cntyl['country'] = df_cntyl['country'].str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The demographic column names have many spaces and capitalization, so I adjust them to be DWH-friendly\n",
    "df_demo.columns=['city', 'state', 'median_age', 'male_population', 'female_population',\n",
    "       'total_population', 'number_of_veterans', 'foreign_born',\n",
    "       'average_household_size', 'state_code', 'race', 'count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "Here, I build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immigration data\n",
    "\n",
    "With the cleanups we already did, the immigration data should actually be fine as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sas_dwh = df_sas_clean_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather data: augment weather data with cntyl code\n",
    "\n",
    "In order to be able to join the weather data to the immigration data, the cntyl country code needs to be available in the weather data. This is done via a join on the country field. Ideally, this join would be fuzzy, but for now I will just perform a rigid join.\n",
    "\n",
    "We leave the actual aggreagation of weather data over time to the data scientist. This implies that country names will have multiple appearances, and hence cannot be used as an index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_dwh = pd.merge(left=df_weather, right=df_cntyl, \n",
    "                          left_on='country', right_on='country',\n",
    "                          how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "      <th>country</th>\n",
       "      <th>i94cntyl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>4.384</td>\n",
       "      <td>2.294</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>1.530</td>\n",
       "      <td>4.680</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>6.702</td>\n",
       "      <td>1.789</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>11.609</td>\n",
       "      <td>1.577</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>15.342</td>\n",
       "      <td>1.410</td>\n",
       "      <td>ÅLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  average_temperature  average_temperature_uncertainty country  \\\n",
       "0 1743-11-01                4.384                            2.294   ÅLAND   \n",
       "1 1744-04-01                1.530                            4.680   ÅLAND   \n",
       "2 1744-05-01                6.702                            1.789   ÅLAND   \n",
       "3 1744-06-01               11.609                            1.577   ÅLAND   \n",
       "4 1744-07-01               15.342                            1.410   ÅLAND   \n",
       "\n",
       "   i94cntyl  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_dwh.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep countries that are in the imigration data\n",
    "i94cntyl_in_sas = list(set(df_sas_dwh.select(\"i94cit\").distinct().toPandas()['i94cit'] \\\n",
    "+ df_sas_dwh.select(\"i94res\").distinct().toPandas()['i94res']))\n",
    "i94cntyl_in_sas = [int(x) for x in i94cntyl_in_sas if str(x) != 'nan']\n",
    "\n",
    "df_weather_dwh = df_weather_dwh[df_weather_dwh['i94cntyl'].notnull()]\n",
    "df_weather_dwh = df_weather_dwh[df_weather_dwh['i94cntyl'].isin(i94cntyl_in_sas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "      <th>country</th>\n",
       "      <th>i94cntyl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49091</th>\n",
       "      <td>1824-01-01</td>\n",
       "      <td>25.146</td>\n",
       "      <td>0.874</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49092</th>\n",
       "      <td>1824-02-01</td>\n",
       "      <td>24.806</td>\n",
       "      <td>2.374</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49093</th>\n",
       "      <td>1824-03-01</td>\n",
       "      <td>25.318</td>\n",
       "      <td>1.090</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49094</th>\n",
       "      <td>1824-04-01</td>\n",
       "      <td>26.430</td>\n",
       "      <td>2.173</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49095</th>\n",
       "      <td>1824-05-01</td>\n",
       "      <td>26.553</td>\n",
       "      <td>1.217</td>\n",
       "      <td>BARBADOS</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  average_temperature  average_temperature_uncertainty  \\\n",
       "49091 1824-01-01               25.146                            0.874   \n",
       "49092 1824-02-01               24.806                            2.374   \n",
       "49093 1824-03-01               25.318                            1.090   \n",
       "49094 1824-04-01               26.430                            2.173   \n",
       "49095 1824-05-01               26.553                            1.217   \n",
       "\n",
       "        country  i94cntyl  \n",
       "49091  BARBADOS     513.0  \n",
       "49092  BARBADOS     513.0  \n",
       "49093  BARBADOS     513.0  \n",
       "49094  BARBADOS     513.0  \n",
       "49095  BARBADOS     513.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_dwh.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### State data: aggregate demographic data on state level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aggregate the available numeric data on a city level for each state. Since we don't have access to total state demographics in this data set, we express the male population, female population, veteran number and foreign born number as fractions of total pupolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_dwh = df_demo[['state_code', 'state']].drop_duplicates().set_index('state_code')\\\n",
    ".join(df_demo.groupby(['state_code'])['male_population', 'female_population',\\\n",
    "                                      'total_population', 'number_of_veterans', 'foreign_born'].agg('sum'))\\\n",
    ".join(df_demo.groupby(['state_code'])['median_age', 'average_household_size'].agg('median'))\n",
    "\n",
    "df_demo_dwh['male_population'] = df_demo_dwh['male_population']/df_demo_dwh['total_population']\n",
    "df_demo_dwh['female_population'] = df_demo_dwh['female_population']/df_demo_dwh['total_population']\n",
    "df_demo_dwh['number_of_veterans'] = df_demo_dwh['number_of_veterans']/df_demo_dwh['total_population']\n",
    "df_demo_dwh['foreign_born'] = df_demo_dwh['foreign_born']/df_demo_dwh['total_population']\n",
    "\n",
    "df_demo_dwh = df_demo_dwh.drop(['total_population'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>median_age</th>\n",
       "      <th>average_household_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>0.478574</td>\n",
       "      <td>0.521426</td>\n",
       "      <td>0.048885</td>\n",
       "      <td>0.175131</td>\n",
       "      <td>35.9</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>0.484253</td>\n",
       "      <td>0.515747</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>0.257458</td>\n",
       "      <td>34.9</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.474154</td>\n",
       "      <td>0.525846</td>\n",
       "      <td>0.068347</td>\n",
       "      <td>0.048911</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>California</td>\n",
       "      <td>0.494601</td>\n",
       "      <td>0.505399</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>0.300214</td>\n",
       "      <td>35.8</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>0.493871</td>\n",
       "      <td>0.506129</td>\n",
       "      <td>0.021156</td>\n",
       "      <td>0.335845</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    state  male_population  female_population  \\\n",
       "state_code                                                      \n",
       "MD               Maryland         0.478574           0.521426   \n",
       "MA          Massachusetts         0.484253           0.515747   \n",
       "AL                Alabama         0.474154           0.525846   \n",
       "CA             California         0.494601           0.505399   \n",
       "NJ             New Jersey         0.493871           0.506129   \n",
       "\n",
       "            number_of_veterans  foreign_born  median_age  \\\n",
       "state_code                                                 \n",
       "MD                    0.048885      0.175131        35.9   \n",
       "MA                    0.032929      0.257458        34.9   \n",
       "AL                    0.068347      0.048911        38.0   \n",
       "CA                    0.037402      0.300214        35.8   \n",
       "NJ                    0.021156      0.335845        34.6   \n",
       "\n",
       "            average_household_size  \n",
       "state_code                          \n",
       "MD                            2.64  \n",
       "MA                            2.43  \n",
       "AL                            2.41  \n",
       "CA                            3.06  \n",
       "NJ                            2.85  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_dwh.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the data above, we can also extract the \"race distribution\" of each state in a similar fashion. This table acts as an additinal dimension table for each state code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_race_dwh = pd.DataFrame(df_demo.groupby(['state_code', 'race'])['count'].agg('sum'))\\\n",
    ".join(df_demo.groupby(['state_code'])['count'].agg('sum'), rsuffix='_total')\n",
    "\n",
    "df_demo_race_dwh['fraction']=df_demo_race_dwh['count']/df_demo_race_dwh['count_total']\n",
    "df_demo_race_dwh = pd.DataFrame(df_demo_race_dwh['fraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fraction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AK</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <td>0.108078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>0.109524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African-American</th>\n",
       "      <td>0.068724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <td>0.081079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.632595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AL</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <td>0.007375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>0.026245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African-American</th>\n",
       "      <td>0.475360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <td>0.035864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.455155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              fraction\n",
       "state_code race                                       \n",
       "AK         American Indian and Alaska Native  0.108078\n",
       "           Asian                              0.109524\n",
       "           Black or African-American          0.068724\n",
       "           Hispanic or Latino                 0.081079\n",
       "           White                              0.632595\n",
       "AL         American Indian and Alaska Native  0.007375\n",
       "           Asian                              0.026245\n",
       "           Black or African-American          0.475360\n",
       "           Hispanic or Latino                 0.035864\n",
       "           White                              0.455155"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_race_dwh.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### State data from sas: not used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data only contains information which is already available in the state data above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94addr</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  i94addr       state\n",
       "0      AL     ALABAMA\n",
       "1      AK      ALASKA\n",
       "2      AZ     ARIZONA\n",
       "3      AR    ARKANSAS\n",
       "4      CA  CALIFORNIA"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_addr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mode data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mode data can be taken as-is with the correct index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode_dwh=df_mode.set_index('i94mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94mode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOT REPORTED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mode\n",
       "i94mode              \n",
       "1                 AIR\n",
       "2                 SEA\n",
       "3                LAND\n",
       "9        NOT REPORTED"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode_dwh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visa data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visa data can be taken as-is with the correct index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visa_dwh = df_visa.set_index('i94visa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94visa</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             visa\n",
       "i94visa          \n",
       "   1     BUSINESS\n",
       "   2     PLEASURE\n",
       "   3      STUDENT"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visa_dwh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Airport data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we extracted df_port from the sas data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94port</th>\n",
       "      <th>port</th>\n",
       "      <th>addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  i94port                      port addr\n",
       "0     ALC                     ALCAN   AK\n",
       "1     ANC                 ANCHORAGE   AK\n",
       "2     BAR  BAKER AAF - BAKER ISLAND   AK\n",
       "3     DAC             DALTONS CACHE   AK\n",
       "4     PIZ    DEW STATION PT LAY DEW   AK"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can attempt to combine this information with the available airport information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport_dwh = df_port.set_index('i94port').join(df_airport.set_index('ident'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The join is acctually sucesfful in some occasions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_airport_dwh[df_airport_dwh['type'].notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port</th>\n",
       "      <th>addr</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94port</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5KE</th>\n",
       "      <td>KETCHIKAN</td>\n",
       "      <td>AK</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Ketchikan Harbor Seaplane Base</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Ketchikan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WFB</td>\n",
       "      <td>5KE</td>\n",
       "      <td>-131.677002, 55.349899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOS</th>\n",
       "      <td>MOSES POINT INTERMEDIATE</td>\n",
       "      <td>AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Moses Point Airport</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Elim</td>\n",
       "      <td>MOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOS</td>\n",
       "      <td>-162.0570068359375, 64.69819641113281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOM</th>\n",
       "      <td>NOM</td>\n",
       "      <td>AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nomad River Airport</td>\n",
       "      <td>305.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>PG</td>\n",
       "      <td>PG-WPD</td>\n",
       "      <td>Nomad River</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOM</td>\n",
       "      <td>NDR</td>\n",
       "      <td>142.234166667, -6.294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             port addr           type  \\\n",
       "i94port                                                 \n",
       "5KE                     KETCHIKAN   AK  seaplane_base   \n",
       "MOS      MOSES POINT INTERMEDIATE   AK  small_airport   \n",
       "NOM                           NOM   AK  small_airport   \n",
       "\n",
       "                                   name  elevation_ft continent iso_country  \\\n",
       "i94port                                                                       \n",
       "5KE      Ketchikan Harbor Seaplane Base           NaN       NaN          US   \n",
       "MOS                 Moses Point Airport          14.0       NaN          US   \n",
       "NOM                 Nomad River Airport         305.0        OC          PG   \n",
       "\n",
       "        iso_region municipality gps_code iata_code local_code  \\\n",
       "i94port                                                         \n",
       "5KE          US-AK    Ketchikan      NaN       WFB        5KE   \n",
       "MOS          US-AK         Elim      MOS       NaN        MOS   \n",
       "NOM         PG-WPD  Nomad River      NaN       NOM        NDR   \n",
       "\n",
       "                                   coordinates  \n",
       "i94port                                         \n",
       "5KE                     -131.677002, 55.349899  \n",
       "MOS      -162.0570068359375, 64.69819641113281  \n",
       "NOM                      142.234166667, -6.294  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_dwh[df_airport_dwh['type'].notnull()].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality check: is addr same as iso region?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
